import sys
import json
import os
import re

# Á¶ÅÁî®Âπ∂Ë°å‰ª•Èò≤Ê≠ªÈîÅ
os.environ["TOKENIZERS_PARALLELISM"] = "false"

try:
    from dotenv import load_dotenv
    from openai import OpenAI
    import pdfplumber
    from bertopic import BERTopic
    from sklearn.feature_extraction.text import CountVectorizer
except Exception as e:
    print(json.dumps({"error": f"Â∫ìÂØºÂÖ•Â§±Ë¥•: {str(e)}"}))
    sys.exit(1)

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if len(sys.argv) < 2:
    print(json.dumps({"error": "Áº∫Â∞ë PDF Êñá‰ª∂Ë∑ØÂæÑ"}))
    sys.exit(1)

pdf_path = sys.argv[1]
base_filename = os.path.basename(pdf_path)

# 1. ÊñáÊú¨ÊèêÂèñ
def extract_text_from_pdf(path):
    text_list = []
    try:
        with pdfplumber.open(path) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    lines = text.split("\n")
                    for line in lines:
                        line = line.strip()
                        if re.search(r'Page \d+ of \d+', line): continue
                        if len(line) < 10: continue 
                        text_list.append(line)
    except Exception as e:
        return []
    return text_list

texts = extract_text_from_pdf(pdf_path)

if not texts or len(texts) < 5:
    print(json.dumps({"error": "PDF ÂÜÖÂÆπÂ§™Â∞ëÔºåÊó†Ê≥ïÂàÜÊûê"}))
    sys.exit(1)

full_doc_text = "\n".join(texts)[:120000] # Êà™ÂèñÂÖ®Êñá

try:
    client = OpenAI(api_key=api_key)

    # 2. ËøêË°å BERTopic
    vectorizer_model = CountVectorizer(stop_words="english", ngram_range=(1, 2))
    topic_model = BERTopic(
        vectorizer_model=vectorizer_model,
        language="english", 
        calculate_probabilities=False,
        nr_topics=6 
    )
    
    topics, probs = topic_model.fit_transform(texts)
    topic_info = topic_model.get_topic_info()
    top_topics = topic_info[topic_info['Topic'] != -1].head(5)
    
    topic_structure_data = "„ÄêÁÆóÊ≥ïÊèêÂèñÁöÑ‰∏ªÈ¢òÁ∫øÁ¥¢„Äë:\n"
    for index, row in top_topics.iterrows():
        topic_structure_data += f"- {row['Name']}\n"

    # 3. ÁîüÊàêÁªºËø∞
    prompt = f"""
    ‰Ω†ÊòØ‰∏Ä‰∏™ÊñáÊ°£Âä©Êâã„ÄÇËØ∑Ê†πÊçÆ‰∏ãÊñπ‰ø°ÊÅØÁîüÊàê JSON„ÄÇ
    
    1. "summary": 100-200Â≠óÊñáÊ°£ÁªºËø∞ÔºåËØ≠Ê∞î‰∫≤Âàá„ÄÇ
    2. "topics": 3-5‰∏™Ê†∏ÂøÉ‰∏ªÈ¢òÊï∞ÁªÑ (emoji, title, description)„ÄÇ

    {topic_structure_data}
    „ÄêÊñáÊ°£ÂÖ®ÊñáÁâáÊÆµ„Äë:
    {full_doc_text[:5000]}... (ÂêéÁï•)
    """

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )
    
    ai_response = completion.choices[0].message.content
    
    # üåü Ê†∏ÂøÉ‰øÆÊ≠£ÔºöÁ°Æ‰øùËøîÂõû fullText Âíå serverFilename
    result = json.loads(ai_response)
    result['serverFilename'] = base_filename
    result['fullText'] = full_doc_text 
    
    print(json.dumps(result, ensure_ascii=False))

except Exception as e:
    import traceback
    # ÊâìÂç∞ÈîôËØØÂ†ÜÊ†àÂà∞ stderr ‰ª•‰æøË∞ÉËØï
    traceback.print_exc(file=sys.stderr)
    print(json.dumps({"error": str(e)}))
    sys.exit(1)